{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjbfgm-2uOO",
        "outputId": "2bb95f49-feb3-4e50-a3f7-d0ac2cdd27a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo | grep MemTotal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56kaeiKi28VK",
        "outputId": "2c723268-9b73-4b61-9b13-8a86da5bbb6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       53470708 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGC70yewlWC3",
        "outputId": "f1785895-b8bb-4ddb-c809-9e7cfeec6d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,661 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,698 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 21.4 MB in 4s (5,130 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model reloaded successfully!\n",
            "Cleaned data loaded successfully!\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+\n",
            "|FSA|      DATE|HOUR|CUSTOMER_TYPE|PRICE_PLAN|TOTAL_CONSUMPTION|PREMISE_COUNT|AVG_CONSUMPTION_PER_PREMISE|YEAR|MONTH|DAY|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+\n",
            "|M1V|2024-07-01|   1|    SGS <50kW|    Tiered|           3125.6|         1716|         1.8214452214452215|2024|    7|  1|\n",
            "|L7M|2024-07-01|   1|    SGS <50kW|       TOU|           1563.8|          683|         2.2896046852122987|2024|    7|  1|\n",
            "|L9W|2024-07-01|   1|  Residential|    Tiered|            925.0|         1232|         0.7508116883116883|2024|    7|  1|\n",
            "|M2J|2024-07-01|   1|    SGS <50kW|    Tiered|            598.0|          267|         2.2397003745318353|2024|    7|  1|\n",
            "|K2C|2024-07-01|   1|  Residential|       TOU|           5095.2|         7714|         0.6605133523463832|2024|    7|  1|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Set Spark version\n",
        "spark_version = 'spark-3.5.4'\n",
        "os.environ['SPARK_VERSION'] = spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ReadBestModel\").getOrCreate()\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the best trained model\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "# Define the custom metric\n",
        "def mse(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Load the pre-trained best model\n",
        "best_model_path = \"/content/drive/My Drive/TeamFiles/best_neural_network.h5\"\n",
        "best_model = tf.keras.models.load_model(best_model_path, custom_objects={\"mse\": mse})\n",
        "print(\"Best model reloaded successfully!\")\n",
        "\n",
        "# Load cleaned data\n",
        "file_path = \"/content/drive/My Drive/TeamFiles/cleaned_data.parquet\"\n",
        "cleaned_df = spark.read.parquet(file_path)\n",
        "\n",
        "print(\"Cleaned data loaded successfully!\")\n",
        "cleaned_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "# Add row_id BEFORE train-test split\n",
        "cleaned_df = cleaned_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
        "\n",
        "# Show first few rows to verify row_id\n",
        "cleaned_df.show(5)\n"
      ],
      "metadata": {
        "id": "1DuaheaamXCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0917d6-fb9e-47c6-bc7e-1c62debd666e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+\n",
            "|FSA|      DATE|HOUR|CUSTOMER_TYPE|PRICE_PLAN|TOTAL_CONSUMPTION|PREMISE_COUNT|AVG_CONSUMPTION_PER_PREMISE|YEAR|MONTH|DAY|    row_id|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+\n",
            "|M1V|2024-07-01|   1|    SGS <50kW|    Tiered|           3125.6|         1716|         1.8214452214452215|2024|    7|  1|8589934592|\n",
            "|L7M|2024-07-01|   1|    SGS <50kW|       TOU|           1563.8|          683|         2.2896046852122987|2024|    7|  1|8589934593|\n",
            "|L9W|2024-07-01|   1|  Residential|    Tiered|            925.0|         1232|         0.7508116883116883|2024|    7|  1|8589934594|\n",
            "|M2J|2024-07-01|   1|    SGS <50kW|    Tiered|            598.0|          267|         2.2397003745318353|2024|    7|  1|8589934595|\n",
            "|K2C|2024-07-01|   1|  Residential|       TOU|           5095.2|         7714|         0.6605133523463832|2024|    7|  1|8589934596|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Encode categorical columns\n",
        "customer_type_indexer = StringIndexer(inputCol=\"CUSTOMER_TYPE\", outputCol=\"CUSTOMER_TYPE_INDEX\")\n",
        "price_plan_indexer = StringIndexer(inputCol=\"PRICE_PLAN\", outputCol=\"PRICE_PLAN_INDEX\")\n",
        "\n",
        "# Assemble feature columns (keeping all important features)\n",
        "feature_columns = [\n",
        "    \"HOUR\", \"PREMISE_COUNT\", \"AVG_CONSUMPTION_PER_PREMISE\",\n",
        "    \"CUSTOMER_TYPE_INDEX\", \"PRICE_PLAN_INDEX\", \"YEAR\", \"MONTH\", \"DAY\"\n",
        "]\n",
        "\n",
        "# Assemble & scale features\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[customer_type_indexer, price_plan_indexer, assembler, scaler])\n",
        "\n",
        "# Apply transformations\n",
        "prepared_data = pipeline.fit(cleaned_df).transform(cleaned_df)\n",
        "\n",
        "print(\"Data successfully transformed for prediction!\")\n",
        "prepared_data.show(5)\n"
      ],
      "metadata": {
        "id": "wh7zZmqimaWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edd75ab-0258-4ac9-c4b1-b296d05126a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully transformed for prediction!\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "|FSA|      DATE|HOUR|CUSTOMER_TYPE|PRICE_PLAN|TOTAL_CONSUMPTION|PREMISE_COUNT|AVG_CONSUMPTION_PER_PREMISE|YEAR|MONTH|DAY|    row_id|CUSTOMER_TYPE_INDEX|PRICE_PLAN_INDEX|            features|     scaled_features|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "|M1V|2024-07-01|   1|    SGS <50kW|    Tiered|           3125.6|         1716|         1.8214452214452215|2024|    7|  1|8589934592|                1.0|             1.0|[1.0,1716.0,1.821...|[0.0,0.0118100395...|\n",
            "|L7M|2024-07-01|   1|    SGS <50kW|       TOU|           1563.8|          683|         2.2896046852122987|2024|    7|  1|8589934593|                1.0|             0.0|[1.0,683.0,2.2896...|[0.0,0.0046379226...|\n",
            "|L9W|2024-07-01|   1|  Residential|    Tiered|            925.0|         1232|         0.7508116883116883|2024|    7|  1|8589934594|                0.0|             1.0|[1.0,1232.0,0.750...|[0.0,0.0084496285...|\n",
            "|M2J|2024-07-01|   1|    SGS <50kW|    Tiered|            598.0|          267|         2.2397003745318353|2024|    7|  1|8589934595|                1.0|             1.0|[1.0,267.0,2.2397...|[0.0,0.0017496354...|\n",
            "|K2C|2024-07-01|   1|  Residential|       TOU|           5095.2|         7714|         0.6605133523463832|2024|    7|  1|8589934596|                0.0|             0.0|[1.0,7714.0,0.660...|(8,[1,2,5,6],[0.0...|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+-----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_data.write.partitionBy(\"MONTH\").mode(\"overwrite\").parquet(\"partitioned_data\")"
      ],
      "metadata": {
        "id": "3PUoOS-9R9Lk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any previous Spark installation\n",
        "!rm -rf spark-3.5.4-bin-hadoop3\n",
        "!rm -rf /usr/local/lib/python*/dist-packages/pyspark\n",
        "!rm -rf /usr/local/lib/python*/dist-packages/py4j\n",
        "\n",
        "# Install Spark and Java again\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.4-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.4-bin-hadoop3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kz0Zu7rokQm",
        "outputId": "71a41583-fd43-444c-a024-9344ac5b6b6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Start a new Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PartitionedPredictions\") \\\n",
        "    .config(\"spark.master\", \"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark restarted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7pz7BSTopBU",
        "outputId": "07ad98a1-316f-43e5-a00a-ec75004b2ff1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark restarted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8_SwHUMo-IS",
        "outputId": "e82c7ed0-a9c7-475d-f4ff-1a40efdeef0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7c4878301f50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_partition = \"partitioned_data/MONTH=11\"\n",
        "\n",
        "try:\n",
        "    print(f\"Trying to load: {test_partition}\")\n",
        "    prepared_data = spark.read.format(\"parquet\").load(test_partition)\n",
        "    prepared_data.show(5)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading partition: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozpfdn__o1zC",
        "outputId": "35e5918e-f2b2-46fc-9acb-ac3b6fbcbaf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to load: partitioned_data/MONTH=11\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "|FSA|      DATE|HOUR|CUSTOMER_TYPE|PRICE_PLAN|TOTAL_CONSUMPTION|PREMISE_COUNT|AVG_CONSUMPTION_PER_PREMISE|YEAR|DAY|    row_id|CUSTOMER_TYPE_INDEX|PRICE_PLAN_INDEX|            features|     scaled_features|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "|N0N|2024-11-02|  23|    SGS <50kW|    Tiered|            141.7|           96|         1.4760416666666665|2024|  2|8591461592|                1.0|             1.0|[23.0,96.0,1.4760...|[0.95652173913043...|\n",
            "|L6R|2024-11-01|   1|  Residential|    Tiered|            697.2|         1177|         0.5923534409515718|2024|  1|8591371119|                0.0|             1.0|[1.0,1177.0,0.592...|[0.0,0.0080677636...|\n",
            "|N0P|2024-11-02|  23|    SGS <50kW|       TOU|           5292.8|         2589|         2.0443414445731944|2024|  2|8591461593|                1.0|             0.0|[23.0,2589.0,2.04...|[0.95652173913043...|\n",
            "|N6C|2024-11-01|   1|  Residential|    Tiered|            850.9|         1832|         0.4644650655021834|2024|  1|8591371120|                0.0|             1.0|[1.0,1832.0,0.464...|[0.0,0.0126154273...|\n",
            "|M6J|2024-11-02|  23|  Residential|    Tiered|            752.0|         1268|         0.5930599369085173|2024|  2|8591461594|                0.0|             1.0|[23.0,1268.0,0.59...|[0.95652173913043...|\n",
            "+---+----------+----+-------------+----------+-----------------+-------------+---------------------------+----+---+----------+-------------------+----------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Path where partitions are stored\n",
        "partitioned_data_path = \"partitioned_data\"\n",
        "\n",
        "# Get the list of available partitions\n",
        "available_partitions = [folder for folder in os.listdir(partitioned_data_path) if folder.startswith(\"MONTH=\")]\n",
        "available_partitions.sort()  # Sort to maintain order\n",
        "\n",
        "print(f\"Found partitions: {available_partitions}\")\n",
        "\n",
        "# Initialize an empty list to store Pandas DataFrames\n",
        "all_prepared_pandas = []\n",
        "\n",
        "# Load each partition separately\n",
        "for partition_folder in available_partitions:\n",
        "    partition_path = f\"{partitioned_data_path}/{partition_folder}\"\n",
        "\n",
        "    print(f\"Loading partition: {partition_path}\")\n",
        "\n",
        "    try:\n",
        "        # Read partitioned data from Spark\n",
        "        prepared_data = spark.read.format(\"parquet\").load(partition_path)\n",
        "\n",
        "        # Convert Spark DataFrame to Pandas\n",
        "        prepared_pandas = prepared_data.select(\n",
        "            \"row_id\", \"FSA\", \"DATE\", \"HOUR\", \"CUSTOMER_TYPE\", \"PRICE_PLAN\",\n",
        "            \"PREMISE_COUNT\", \"TOTAL_CONSUMPTION\", \"scaled_features\"\n",
        "        ).toPandas()\n",
        "\n",
        "        # Store in the list for merging later\n",
        "        all_prepared_pandas.append(prepared_pandas)\n",
        "\n",
        "        print(f\"Successfully loaded partition: {partition_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing partition {partition_path}: {e}\")\n",
        "\n",
        "# Merge all partitions into one DataFrame (if needed)\n",
        "if all_prepared_pandas:\n",
        "    prepared_pandas = pd.concat(all_prepared_pandas, ignore_index=True)\n",
        "    X_full = np.array(prepared_pandas[\"scaled_features\"].tolist())\n",
        "    print(f\"Data ready for prediction! Shape: {X_full.shape}\")\n",
        "else:\n",
        "    prepared_pandas = pd.DataFrame()\n",
        "    print(\"No valid partitions found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cup45xppEvD",
        "outputId": "da536e8b-2d32-42ca-8535-278f30c543ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found partitions: ['MONTH=11', 'MONTH=4', 'MONTH=7']\n",
            "Loading partition: partitioned_data/MONTH=11\n",
            "Successfully loaded partition: partitioned_data/MONTH=11\n",
            "Loading partition: partitioned_data/MONTH=4\n",
            "Successfully loaded partition: partitioned_data/MONTH=4\n",
            "Loading partition: partitioned_data/MONTH=7\n",
            "Successfully loaded partition: partitioned_data/MONTH=7\n",
            "Data ready for prediction! Shape: (4180454, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert features into NumPy array\n",
        "X_full = np.array(prepared_pandas[\"scaled_features\"].tolist(), dtype=np.float32)\n",
        "\n",
        "print(f\"Feature array shape: {X_full.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGtLbuINpMEZ",
        "outputId": "70cdfaac-f558-4e12-9401-4956e5bf1aa4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature array shape: (4180454, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best trained model\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "# Define the custom metric\n",
        "def mse(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Load the pre-trained best model\n",
        "best_model_path = \"/content/drive/My Drive/TeamFiles/best_neural_network.h5\"\n",
        "best_model = tf.keras.models.load_model(best_model_path, custom_objects={\"mse\": mse})\n",
        "print(\"Best model reloaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctqXtRMUpQqP",
        "outputId": "7886d25e-c187-4a0f-ba1f-78e6f403d7f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model reloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_full_pred = best_model.predict(X_full)\n",
        "\n",
        "# Convert predictions to Pandas DataFrame\n",
        "predictions_pandas = pd.DataFrame({\n",
        "    \"row_id\": prepared_pandas[\"row_id\"],\n",
        "    \"PREDICTED_CONSUMPTION\": y_full_pred.flatten()\n",
        "})\n",
        "\n",
        "print(\"Predictions successfully generated!\")\n",
        "print(predictions_pandas.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvRmCOqDpVgd",
        "outputId": "0dc24ff0-c577-47a0-e19a-ccb9eb37be26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130640/130640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1ms/step\n",
            "Predictions successfully generated!\n",
            "       row_id  PREDICTED_CONSUMPTION\n",
            "0  8591461592             107.067856\n",
            "1  8591371119             702.102112\n",
            "2  8591461593            5241.788086\n",
            "3  8591371120             861.344971\n",
            "4  8591461594             788.427124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge predictions with prepared data\n",
        "merged_pandas = prepared_pandas.merge(predictions_pandas, on=\"row_id\", how=\"left\")\n",
        "\n",
        "# Drop row_id as it's no longer needed\n",
        "merged_pandas = merged_pandas.drop(columns=[\"row_id\"])\n",
        "\n",
        "# Convert back to Spark DataFrame\n",
        "final_cleaned_df = spark.createDataFrame(merged_pandas)\n",
        "\n",
        "print(\"Predictions merged successfully into the dataset!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WKccztIpaH3",
        "outputId": "4e91713c-b6d0-4ac6-9f0c-c763decdd9f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions merged successfully into the dataset!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "J-cOXQJBqwYi",
        "outputId": "7064c670-a0bf-4788-a550-4d455696d0bc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)                 │           \u001b[38;5;34m1,296\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)                 │          \u001b[38;5;34m34,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │          \u001b[38;5;34m11,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m)                 │          \u001b[38;5;34m11,760\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m176\u001b[0m)                 │          \u001b[38;5;34m42,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)                 │          \u001b[38;5;34m36,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m209\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,760</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">42,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m138,867\u001b[0m (542.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">138,867</span> (542.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m138,865\u001b[0m (542.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">138,865</span> (542.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert `scaled_features` to a string format\n",
        "final_cleaned_df = final_cleaned_df.withColumn(\"scaled_features\", col(\"scaled_features\").cast(\"string\"))\n",
        "\n",
        "# Define CSV save path\n",
        "local_csv_path = \"/content/final_cleaned_data_with_predictions.csv\"\n",
        "\n",
        "# Save to CSV\n",
        "final_cleaned_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(local_csv_path)\n",
        "\n",
        "print(f\"CSV saved locally: {local_csv_path}\")\n"
      ],
      "metadata": {
        "id": "kR_HqR0pAqrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(local_csv_path)\n"
      ],
      "metadata": {
        "id": "kDS7YJQ9yJHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total rows in combined dataset: {final_cleaned_df.count()}\")"
      ],
      "metadata": {
        "id": "tPbYzemrwvaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}